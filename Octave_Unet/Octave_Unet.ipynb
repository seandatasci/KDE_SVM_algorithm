{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Octave Unet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igYDONQUc_NC",
        "colab_type": "code",
        "outputId": "7c29a8c6-0774-4af7-e481-15976565a28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "!git clone https://github.com/zhixuhao/unet.git\n",
        "!cp -r unet/* ./\n",
        "!pip install keras-rectified-adam\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet'...\n",
            "remote: Enumerating objects: 394, done.\u001b[K\n",
            "remote: Total 394 (delta 0), reused 0 (delta 0), pack-reused 394\u001b[K\n",
            "Receiving objects: 100% (394/394), 44.91 MiB | 38.81 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Collecting keras-rectified-adam\n",
            "  Downloading https://files.pythonhosted.org/packages/21/79/9521f66b92186702cb58a214c1b923b416266381cd824e15a1733f6a5b06/keras-rectified-adam-0.17.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (1.16.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.1.0)\n",
            "Building wheels for collected packages: keras-rectified-adam\n",
            "  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.17.0-cp36-none-any.whl size=14781 sha256=256cd1f1fab127b2841c316d1b38e2f5befeaead2c6dfb6f10a89c18a00ff6a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/01/27/3a934e1a5644f5b93c720422a6ef97034ea78a21ba71cfb549\n",
            "Successfully built keras-rectified-adam\n",
            "Installing collected packages: keras-rectified-adam\n",
            "Successfully installed keras-rectified-adam-0.17.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_m8gGwFSPsi",
        "colab_type": "code",
        "outputId": "bafde6c5-7187-424c-d588-4fa4139812c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile keras_octave_conv.py\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "__all__ = ['OctaveConv2D', 'octave_conv_2d']\n",
        "\n",
        "\n",
        "class OctaveConv2D(Layer):\n",
        "    \"\"\"Octave convolutions.\n",
        "    # Arguments\n",
        "        octave: The division of the spatial dimensions by a power of 2.\n",
        "        ratio_out: The ratio of filters for lower spatial resolution.\n",
        "    # References\n",
        "        - [Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution]\n",
        "          (https://arxiv.org/pdf/1904.05049.pdf)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 filters,\n",
        "                 kernel_size=(3,3),\n",
        "                 octave=2,\n",
        "                 ratio_out=0.125,\n",
        "                 strides=(1, 1),\n",
        "                 data_format=None,\n",
        "                 dilation_rate=(1, 1),\n",
        "                 activation=None,\n",
        "                 use_bias=False,\n",
        "                 use_transpose=False,\n",
        "                 kernel_initializer='he_normal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(OctaveConv2D, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.octave = octave\n",
        "        self.ratio_out = ratio_out\n",
        "        self.strides = strides\n",
        "        self.data_format = data_format\n",
        "        self.dilation_rate = dilation_rate\n",
        "        self.use_bias = use_bias\n",
        "        self.use_transpose = use_transpose\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.bias_regularizer = bias_regularizer\n",
        "        self.activity_regularizer = activity_regularizer\n",
        "        self.kernel_constraint = kernel_constraint\n",
        "        self.bias_constraint = bias_constraint\n",
        "\n",
        "        self.filters_low = int(filters * self.ratio_out)\n",
        "        self.filters_high = filters - self.filters_low\n",
        "\n",
        "        self.conv_high_to_high, self.conv_low_to_high = None, None\n",
        "        if self.use_transpose:\n",
        "          if self.filters_high > 0:\n",
        "              self.conv_high_to_high = self._init_transconv(self.filters_high, name='{}-Trans-Conv2D-HH'.format(self.name))\n",
        "              self.conv_low_to_high = self._init_transconv(self.filters_high, name='{}-Conv2D-LH'.format(self.name))\n",
        "          self.conv_low_to_low, self.conv_high_to_low = None, None\n",
        "          if self.filters_low > 0:\n",
        "              self.conv_low_to_low = self._init_transconv(self.filters_low, name='{}-Trans-Conv2D-HL'.format(self.name))\n",
        "              self.conv_high_to_low = self._init_transconv(self.filters_low, name='{}-Trans-Conv2D-LL'.format(self.name))\n",
        "          self.pooling = AveragePooling2D(\n",
        "              pool_size=self.octave,\n",
        "              padding='valid',\n",
        "              data_format=data_format,\n",
        "              name='{}-AveragePooling2D'.format(self.name),\n",
        "          )\n",
        "          self.up_sampling = UpSampling2D(\n",
        "              size=self.octave,\n",
        "              data_format=data_format,\n",
        "              name='{}-UpSampling2D'.format(self.name)\n",
        "          )\n",
        "        else:\n",
        "          if self.filters_high > 0:\n",
        "              self.conv_high_to_high = self._init_conv(self.filters_high, name='{}-Conv2D-HH'.format(self.name))\n",
        "              self.conv_low_to_high = self._init_conv(self.filters_high, name='{}-Conv2D-LH'.format(self.name))\n",
        "          self.conv_low_to_low, self.conv_high_to_low = None, None\n",
        "          if self.filters_low > 0:\n",
        "              self.conv_low_to_low = self._init_conv(self.filters_low, name='{}-Conv2D-HL'.format(self.name))\n",
        "              self.conv_high_to_low = self._init_conv(self.filters_low, name='{}-Conv2D-LL'.format(self.name))\n",
        "          self.pooling = AveragePooling2D(\n",
        "              pool_size=self.octave,\n",
        "              padding='valid',\n",
        "              data_format=data_format,\n",
        "              name='{}-AveragePooling2D'.format(self.name),\n",
        "          )\n",
        "          self.up_sampling = UpSampling2D(\n",
        "              size=self.octave,\n",
        "              data_format=data_format,\n",
        "              name='{}-UpSampling2D'.format(self.name)\n",
        "          )\n",
        "    def _init_transconv(self, filters, name):\n",
        "        return Conv2DTranspose(\n",
        "            filters=filters,\n",
        "            kernel_size=self.kernel_size,\n",
        "            strides=self.strides,\n",
        "            padding='same',\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate,\n",
        "            use_bias=self.use_bias,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "            kernel_regularizer=self.kernel_regularizer,\n",
        "            bias_regularizer=self.bias_regularizer,\n",
        "            activity_regularizer=self.activity_regularizer,\n",
        "            kernel_constraint=self.kernel_constraint,\n",
        "            bias_constraint=self.bias_constraint,\n",
        "            name=name,\n",
        "        )\n",
        "\n",
        "    def _init_conv(self, filters, name):\n",
        "        return Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=self.kernel_size,\n",
        "            strides=self.strides,\n",
        "            padding='same',\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate,\n",
        "            use_bias=self.use_bias,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "            kernel_regularizer=self.kernel_regularizer,\n",
        "            bias_regularizer=self.bias_regularizer,\n",
        "            activity_regularizer=self.activity_regularizer,\n",
        "            kernel_constraint=self.kernel_constraint,\n",
        "            bias_constraint=self.bias_constraint,\n",
        "            name=name,\n",
        "        )\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape_high, input_shape_low = input_shape\n",
        "        else:\n",
        "            input_shape_high, input_shape_low = input_shape, None\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis, rows_axis, cols_axis = 1, 2, 3\n",
        "        else:\n",
        "            rows_axis, cols_axis, channel_axis = 1, 2, 3\n",
        "        if input_shape_high[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the higher spatial inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        if input_shape_low is not None and input_shape_low[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the lower spatial inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        if input_shape_high[rows_axis] is not None and input_shape_high[rows_axis] % self.octave != 0 or \\\n",
        "           input_shape_high[cols_axis] is not None and input_shape_high[cols_axis] % self.octave != 0:\n",
        "            raise ValueError('The rows and columns of the higher spatial inputs should be divisible by the octave. '\n",
        "                             'Found {} and {}.'.format(input_shape_high, self.octave))\n",
        "        if input_shape_low is None:\n",
        "            self.conv_low_to_high, self.conv_low_to_low = None, None\n",
        "\n",
        "        if self.conv_high_to_high is not None:\n",
        "            with K.name_scope(self.conv_high_to_high.name):\n",
        "                self.conv_high_to_high.build(input_shape_high)\n",
        "        if self.conv_low_to_high is not None:\n",
        "            with K.name_scope(self.conv_low_to_high.name):\n",
        "                self.conv_low_to_high.build(input_shape_low)\n",
        "        if self.conv_high_to_low is not None:\n",
        "            with K.name_scope(self.conv_high_to_low.name):\n",
        "                self.conv_high_to_low.build(input_shape_high)\n",
        "        if self.conv_low_to_low is not None:\n",
        "            with K.name_scope(self.conv_low_to_low.name):\n",
        "                self.conv_low_to_low.build(input_shape_low)\n",
        "        super(OctaveConv2D, self).build(input_shape)\n",
        "\n",
        "    @property\n",
        "    def trainable_weights(self):\n",
        "        weights = []\n",
        "        if self.conv_high_to_high is not None:\n",
        "            weights += self.conv_high_to_high.trainable_weights\n",
        "        if self.conv_low_to_high is not None:\n",
        "            weights += self.conv_low_to_high.trainable_weights\n",
        "        if self.conv_high_to_low is not None:\n",
        "            weights += self.conv_high_to_low.trainable_weights\n",
        "        if self.conv_low_to_low is not None:\n",
        "            weights += self.conv_low_to_low.trainable_weights\n",
        "        return weights\n",
        "\n",
        "    @property\n",
        "    def non_trainable_weights(self):\n",
        "        weights = []\n",
        "        if self.conv_high_to_high is not None:\n",
        "            weights += self.conv_high_to_high.non_trainable_weights\n",
        "        if self.conv_low_to_high is not None:\n",
        "            weights += self.conv_low_to_high.non_trainable_weights\n",
        "        if self.conv_high_to_low is not None:\n",
        "            weights += self.conv_high_to_low.non_trainable_weights\n",
        "        if self.conv_low_to_low is not None:\n",
        "            weights += self.conv_low_to_low.non_trainable_weights\n",
        "        return weights\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape_high, input_shape_low = input_shape\n",
        "        else:\n",
        "            input_shape_high, input_shape_low = input_shape, None\n",
        "\n",
        "        output_shape_high = None\n",
        "        if self.filters_high > 0:\n",
        "            output_shape_high = self.conv_high_to_high.compute_output_shape(input_shape_high)\n",
        "        output_shape_low = None\n",
        "        if self.filters_low > 0:\n",
        "            output_shape_low = self.conv_high_to_low.compute_output_shape(\n",
        "                self.pooling.compute_output_shape(input_shape_high),\n",
        "            )\n",
        "\n",
        "        if self.filters_low == 0:\n",
        "            return output_shape_high\n",
        "        if self.filters_high == 0:\n",
        "            return output_shape_low\n",
        "        return [output_shape_high, output_shape_low]\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if isinstance(inputs, list):\n",
        "            inputs_high, inputs_low = inputs\n",
        "        else:\n",
        "            inputs_high, inputs_low = inputs, None\n",
        "\n",
        "        outputs_high_to_high, outputs_low_to_high = 0.0, 0.0\n",
        "        if self.use_transpose:\n",
        "          if self.conv_high_to_high is not None:\n",
        "              outputs_high_to_high = self.conv_high_to_high(inputs_high)\n",
        "          if self.conv_low_to_high is not None:\n",
        "              outputs_low_to_high = self.up_sampling(self.conv_low_to_high(inputs_low))\n",
        "          outputs_high = outputs_high_to_high + outputs_low_to_high\n",
        "\n",
        "          outputs_low_to_low, outputs_high_to_low = 0.0, 0.0\n",
        "          if self.conv_low_to_low is not None:\n",
        "              outputs_low_to_low = self.conv_low_to_low(inputs_low)\n",
        "          if self.conv_high_to_low is not None:\n",
        "              outputs_high_to_low = self.pooling(self.conv_high_to_low(inputs_high))\n",
        "          outputs_low = outputs_low_to_low + outputs_high_to_low\n",
        "\n",
        "          if self.filters_low == 0:\n",
        "              return outputs_high\n",
        "          if self.filters_high == 0:\n",
        "              return outputs_low\n",
        "        else:\n",
        "          if self.conv_high_to_high is not None:\n",
        "              outputs_high_to_high = self.conv_high_to_high(inputs_high)\n",
        "          if self.conv_low_to_high is not None:\n",
        "              outputs_low_to_high = self.up_sampling(self.conv_low_to_high(inputs_low))\n",
        "          outputs_high = outputs_high_to_high + outputs_low_to_high\n",
        "\n",
        "          outputs_low_to_low, outputs_high_to_low = 0.0, 0.0\n",
        "          if self.conv_low_to_low is not None:\n",
        "              outputs_low_to_low = self.conv_low_to_low(inputs_low)\n",
        "          if self.conv_high_to_low is not None:\n",
        "              outputs_high_to_low = self.conv_high_to_low(self.pooling(inputs_high))\n",
        "          outputs_low = outputs_low_to_low + outputs_high_to_low\n",
        "\n",
        "          if self.filters_low == 0:\n",
        "              return outputs_high\n",
        "          if self.filters_high == 0:\n",
        "              return outputs_low\n",
        "        return [outputs_high, outputs_low]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'filters': self.filters,\n",
        "            'kernel_size': self.kernel_size,\n",
        "            'octave': self.octave,\n",
        "            'ratio_out': self.ratio_out,\n",
        "            'strides': self.strides,\n",
        "            'data_format': self.data_format,\n",
        "            'dilation_rate': self.dilation_rate,\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': self.kernel_initializer,\n",
        "            'bias_initializer': self.bias_initializer,\n",
        "            'kernel_regularizer': self.kernel_regularizer,\n",
        "            'bias_regularizer': self.bias_regularizer,\n",
        "            'activity_regularizer': self.activity_regularizer,\n",
        "            'kernel_constraint': self.kernel_constraint,\n",
        "            'bias_constraint': self.bias_constraint\n",
        "        }\n",
        "        base_config = super(OctaveConv2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing keras_octave_conv.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8PrIduoVKiQ",
        "colab_type": "code",
        "outputId": "b8ee11a5-6f13-4578-b648-2bb8bb418a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile model.py\n",
        "# model code all in this cell\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from keras_radam.training import RAdamOptimizer\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras_octave_conv import OctaveConv2D\n",
        "      \n",
        "      \n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    # downsampling for lower\n",
        "    low = layers.AveragePooling2D(2)(inputs)\n",
        "    high1, low1 = OctaveConv2D(64)([inputs,low])\n",
        "    high1 = layers.BatchNormalization()(high1)\n",
        "    high1 = layers.Activation(\"relu\")(high1)\n",
        "    low1 = layers.BatchNormalization()(low1)\n",
        "    low1 = layers.Activation(\"relu\")(low1)\n",
        "    high1, low1 = OctaveConv2D(64)([high1, low1])\n",
        "    high1 = layers.BatchNormalization()(high1)\n",
        "    high1 = layers.Activation(\"relu\")(high1)\n",
        "    low1 = layers.BatchNormalization()(low1)\n",
        "    low1 = layers.Activation(\"relu\")(low1)\n",
        "    pool1high = layers.MaxPooling2D(2)(high1)\n",
        "    pool1low = layers.MaxPooling2D(2)(low1)\n",
        "    \n",
        "    high2, low2 = OctaveConv2D(128)([pool1high,pool1low])\n",
        "    high2 = layers.BatchNormalization()(high2)\n",
        "    high2 = layers.Activation(\"relu\")(high2)\n",
        "    low2 = layers.BatchNormalization()(low2)\n",
        "    low2 = layers.Activation(\"relu\")(low2)\n",
        "    high2, low2 = OctaveConv2D(128)([high2, low2])\n",
        "    high2 = layers.BatchNormalization()(high2)\n",
        "    high2 = layers.Activation(\"relu\")(high2)\n",
        "    low2 = layers.BatchNormalization()(low2)\n",
        "    low2 = layers.Activation(\"relu\")(low2)\n",
        "    pool2high = layers.MaxPooling2D(2)(high2)\n",
        "    pool2low = layers.MaxPooling2D(2)(low2)\n",
        "    \n",
        "    high3, low3 = OctaveConv2D(256)([pool2high,pool2low])\n",
        "    high3 = layers.BatchNormalization()(high3)\n",
        "    high3 = layers.Activation(\"relu\")(high3)\n",
        "    low3 = layers.BatchNormalization()(low3)\n",
        "    low3 = layers.Activation(\"relu\")(low3)\n",
        "    high3, low3 = OctaveConv2D(256)([high3, low3])\n",
        "    high3 = layers.BatchNormalization()(high3)\n",
        "    high3 = layers.Activation(\"relu\")(high3)\n",
        "    low3 = layers.BatchNormalization()(low3)\n",
        "    low3 = layers.Activation(\"relu\")(low3)\n",
        "    pool3high = layers.MaxPooling2D(2)(high3)\n",
        "    pool3low = layers.MaxPooling2D(2)(low3)\n",
        "    \n",
        "    high4, low4 = OctaveConv2D(512)([pool3high,pool3low])\n",
        "    high4 = layers.BatchNormalization()(high4)\n",
        "    high4 = layers.Activation(\"relu\")(high4)\n",
        "    low4 = layers.BatchNormalization()(low4)\n",
        "    low4 = layers.Activation(\"relu\")(low4)\n",
        "    high4, low4 = OctaveConv2D(512)([high4, low4])\n",
        "    high4 = layers.BatchNormalization()(high4)\n",
        "    high4 = layers.Activation(\"relu\")(high4)\n",
        "    low4 = layers.BatchNormalization()(low4)\n",
        "    low4 = layers.Activation(\"relu\")(low4)\n",
        "    pool4high = layers.MaxPooling2D(2)(high4)\n",
        "    pool4low = layers.MaxPooling2D(2)(low4)\n",
        "\n",
        "    high5, low5 = OctaveConv2D(1024)([pool4high, pool4low])\n",
        "    high5 = layers.BatchNormalization()(high5)\n",
        "    high5 = layers.Activation(\"relu\")(high5)\n",
        "    low5 = layers.BatchNormalization()(low5)\n",
        "    low5 = layers.Activation(\"relu\")(low5)\n",
        "    high5 = Dropout(0.4)(high5)\n",
        "    low5 = Dropout(0.4)(low5)\n",
        "    high5, low5 = OctaveConv2D(1024)([high5, low5])\n",
        "    high5 = layers.BatchNormalization()(high5)\n",
        "    high5 = layers.Activation(\"relu\")(high5)\n",
        "    low5 = layers.BatchNormalization()(low5)\n",
        "    low5 = layers.Activation(\"relu\")(low5)\n",
        "    high5 = Dropout(0.4)(high5)\n",
        "    low5 = Dropout(0.4)(low5)\n",
        "    \n",
        "    uphigh6, uplow6 = OctaveConv2D(512, use_transpose=True, strides=(2,2))([high5,low5])\n",
        "    uphigh6 = layers.BatchNormalization()(uphigh6)\n",
        "    uphigh6 = layers.Activation(\"relu\")(uphigh6)\n",
        "    uplow6 = layers.BatchNormalization()(uplow6)\n",
        "    uplow6 = layers.Activation(\"relu\")(uplow6)\n",
        "    merge6high = concatenate([high4,uphigh6], axis = 3)\n",
        "    merge6low = concatenate([low4,uplow6], axis = 3)\n",
        "    high6, low6 = OctaveConv2D(512)([merge6high,merge6low])\n",
        "    high6 = layers.BatchNormalization()(high6)\n",
        "    high6 = layers.Activation(\"relu\")(high6)\n",
        "    low6 = layers.BatchNormalization()(low6)\n",
        "    low6 = layers.Activation(\"relu\")(low6)\n",
        "    high6, low6 = OctaveConv2D(512)([high6, low6])\n",
        "    high6 = layers.BatchNormalization()(high6)\n",
        "    high6 = layers.Activation(\"relu\")(high6)\n",
        "    low6 = layers.BatchNormalization()(low6)\n",
        "    low6 = layers.Activation(\"relu\")(low6)\n",
        "\n",
        "\n",
        "    uphigh7, uplow7 = OctaveConv2D(256, use_transpose=True, strides=(2,2))([high6, low6])\n",
        "    uphigh7 = layers.BatchNormalization()(uphigh7)\n",
        "    uphigh7 = layers.Activation(\"relu\")(uphigh7)\n",
        "    uplow7 = layers.BatchNormalization()(uplow7)\n",
        "    uplow7 = layers.Activation(\"relu\")(uplow7)\n",
        "    merge7high = concatenate([high3,uphigh7], axis = 3)\n",
        "    merge7low = concatenate([low3,uplow7], axis = 3)\n",
        "    high7, low7 = OctaveConv2D(256)([merge7high, merge7low])\n",
        "    high7 = layers.BatchNormalization()(high7)\n",
        "    high7 = layers.Activation(\"relu\")(high7)\n",
        "    low7 = layers.BatchNormalization()(low7)\n",
        "    low7 = layers.Activation(\"relu\")(low7)\n",
        "    high7, low7 = OctaveConv2D(256)([high7, low7])\n",
        "    high7 = layers.BatchNormalization()(high7)\n",
        "    high7 = layers.Activation(\"relu\")(high7)\n",
        "    low7 = layers.BatchNormalization()(low7)\n",
        "    low7 = layers.Activation(\"relu\")(low7)\n",
        "\n",
        "    uphigh8, uplow8 = OctaveConv2D(128, use_transpose=True, strides=(2,2))([high7, low7])\n",
        "    uphigh8 = layers.BatchNormalization()(uphigh8)\n",
        "    uphigh8 = layers.Activation(\"relu\")(uphigh8)\n",
        "    uplow8 = layers.BatchNormalization()(uplow8)\n",
        "    uplow8 = layers.Activation(\"relu\")(uplow8)\n",
        "    merge8high = concatenate([high2,uphigh8], axis = 3)\n",
        "    merge8low = concatenate([low2,uplow8], axis = 3)\n",
        "    high8, low8 = OctaveConv2D(128)([merge8high, merge8low])\n",
        "    high8 = layers.BatchNormalization()(high8)\n",
        "    high8 = layers.Activation(\"relu\")(high8)\n",
        "    low8 = layers.BatchNormalization()(low8)\n",
        "    low8 = layers.Activation(\"relu\")(low8)\n",
        "    high8, low8 = OctaveConv2D(128)([high8, low8])\n",
        "    high8 = layers.BatchNormalization()(high8)\n",
        "    high8 = layers.Activation(\"relu\")(high8)\n",
        "    low8 = layers.BatchNormalization()(low8)\n",
        "    low8 = layers.Activation(\"relu\")(low8)\n",
        "\n",
        "    uphigh9, uplow9 = OctaveConv2D(64, use_transpose=True, strides=(2,2))([high8, low8])\n",
        "    uphigh9 = layers.BatchNormalization()(uphigh9)\n",
        "    uphigh9 = layers.Activation(\"relu\")(uphigh9)\n",
        "    uplow9 = layers.BatchNormalization()(uplow9)\n",
        "    uplow9 = layers.Activation(\"relu\")(uplow9)\n",
        "    merge9high = concatenate([high1,uphigh9], axis = 3)\n",
        "    merge9low = concatenate([low1,uplow9], axis = 3)\n",
        "    high9, low9 = OctaveConv2D(64)([merge9high, merge9low])\n",
        "    high9 = layers.BatchNormalization()(high9)\n",
        "    high9 = layers.Activation(\"relu\")(high9)\n",
        "    low9 = layers.BatchNormalization()(low9)\n",
        "    low9 = layers.Activation(\"relu\")(low9)\n",
        "    high9, low9 = OctaveConv2D(64)([high9, low9])\n",
        "    high9 = layers.BatchNormalization()(high9)\n",
        "    high9 = layers.Activation(\"relu\")(high9)\n",
        "    low9 = layers.BatchNormalization()(low9)\n",
        "    low9 = layers.Activation(\"relu\")(low9)\n",
        "    conv9 = OctaveConv2D(32, ratio_out=0.0)([high9, low9])\n",
        "    conv9 = layers.Activation(\"sigmoid\")(conv9)\n",
        "    conv10 = layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    model.compile(optimizer = RAdamOptimizer(learning_rate=1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgJDTDpuds9s",
        "colab_type": "code",
        "outputId": "b426bebb-34a2-4628-86e3-473b8559af64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from model import *\n",
        "# from data import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bw47tCf6UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        yield (img,mask)\n",
        "        \n",
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "    if(flag_multi_class):\n",
        "        img = img / 255\n",
        "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "        new_mask = np.zeros(mask.shape + (num_class,))\n",
        "        for i in range(num_class):\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[mask == i,i] = 1\n",
        "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "        mask = new_mask\n",
        "    elif(np.max(img) > 1):\n",
        "        img = img / 255\n",
        "        mask = mask /255\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "    return (img,mask)\n",
        "  \n",
        "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
        "    image_arr = []\n",
        "    mask_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        img = io.imread(item,as_gray = image_as_gray)\n",
        "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
        "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
        "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        image_arr.append(img)\n",
        "        mask_arr.append(mask)\n",
        "    image_arr = np.array(image_arr)\n",
        "    mask_arr = np.array(mask_arr)\n",
        "    return image_arr,mask_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfyxJo0YdtNl",
        "colab_type": "code",
        "outputId": "6a07e770-58b1-48a2-c385-463348e50781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args, save_to_dir = 'data/membrane/train/aug')\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 128, 128, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d (OctaveConv2D)    [(None, 256, 256, 56 1152        input_1[0][0]                    \n",
            "                                                                 average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 56) 224         octave_conv2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 8)  32          octave_conv2d[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 56) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 8)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_1 (OctaveConv2D)  [(None, 256, 256, 56 36864       activation[0][0]                 \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 56) 224         octave_conv2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 8)  32          octave_conv2d_1[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 56) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 8)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 56) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 8)    0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_2 (OctaveConv2D)  [(None, 128, 128, 11 73728       max_pooling2d[0][0]              \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 112 448         octave_conv2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          octave_conv2d_2[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 112 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_3 (OctaveConv2D)  [(None, 128, 128, 11 147456      activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128, 128, 112 448         octave_conv2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 16)   64          octave_conv2d_3[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 128, 128, 112 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 16)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 112)  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 16)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_4 (OctaveConv2D)  [(None, 64, 64, 224) 294912      max_pooling2d_2[0][0]            \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 224)  896         octave_conv2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         octave_conv2d_4[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 224)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_5 (OctaveConv2D)  [(None, 64, 64, 224) 589824      activation_8[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_5[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 224)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 224)  0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_6 (OctaveConv2D)  [(None, 32, 32, 448) 1179648     max_pooling2d_4[0][0]            \n",
            "                                                                 max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_6[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 448)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_7 (OctaveConv2D)  [(None, 32, 32, 448) 2359296     activation_12[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_7[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 448)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 448)  0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_8 (OctaveConv2D)  [(None, 16, 16, 896) 4718592     max_pooling2d_6[0][0]            \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 896)  3584        octave_conv2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         octave_conv2d_8[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 896)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 16, 16, 896)  0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 8, 8, 128)    0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_9 (OctaveConv2D)  [(None, 16, 16, 896) 9437184     dropout[0][0]                    \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 896)  3584        octave_conv2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 128)    512         octave_conv2d_9[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 896)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 128)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 16, 16, 896)  0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 8, 8, 128)    0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_10 (OctaveConv2D) [(None, 32, 32, 448) 4718592     dropout_2[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_10[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 448)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 896)  0           activation_14[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 128)  0           activation_15[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_11 (OctaveConv2D) [(None, 32, 32, 448) 4718592     concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_11[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 448)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_12 (OctaveConv2D) [(None, 32, 32, 448) 2359296     activation_22[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_12[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 448)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_13 (OctaveConv2D) [(None, 64, 64, 224) 1179648     activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_13[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 224)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 448)  0           activation_10[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 64)   0           activation_11[0][0]              \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_14 (OctaveConv2D) [(None, 64, 64, 224) 1179648     concatenate_2[0][0]              \n",
            "                                                                 concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_14[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 64, 64, 224)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_15 (OctaveConv2D) [(None, 64, 64, 224) 589824      activation_28[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_15[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 64, 64, 224)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_16 (OctaveConv2D) [(None, 128, 128, 11 294912      activation_30[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 128, 128, 112 448         octave_conv2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_16[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 128, 128, 112 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 64, 64, 16)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 128, 128, 224 0           activation_6[0][0]               \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 32)   0           activation_7[0][0]               \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_17 (OctaveConv2D) [(None, 128, 128, 11 294912      concatenate_4[0][0]              \n",
            "                                                                 concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 128, 128, 112 448         octave_conv2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_17[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 128, 128, 112 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 64, 64, 16)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_18 (OctaveConv2D) [(None, 128, 128, 11 147456      activation_34[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 128, 128, 112 448         octave_conv2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_18[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 128, 128, 112 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 64, 64, 16)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_19 (OctaveConv2D) [(None, 256, 256, 56 73728       activation_36[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_19[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 256, 256, 56) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 128, 128, 8)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256, 256, 112 0           activation_2[0][0]               \n",
            "                                                                 activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 128, 128, 16) 0           activation_3[0][0]               \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_20 (OctaveConv2D) [(None, 256, 256, 56 73728       concatenate_6[0][0]              \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_20[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 256, 256, 56) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 128, 128, 8)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_21 (OctaveConv2D) [(None, 256, 256, 56 36864       activation_40[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_21[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 256, 256, 56) 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 128, 128, 8)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_22 (OctaveConv2D) (None, 256, 256, 32) 18432       activation_42[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 256, 256, 32) 0           octave_conv2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 1)  33          activation_44[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 34,551,713\n",
            "Trainable params: 34,538,017\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5blGp3GdtcJ",
        "colab_type": "code",
        "outputId": "9430a329-e26b-4ed6-9018-8022fc4d9331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30 images belonging to 1 classes.\n",
            "Found 30 images belonging to 1 classes.\n",
            "Epoch 1/5\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.2486 - acc: 0.8913\n",
            "Epoch 00001: loss improved from inf to 0.24859, saving model to unet_membrane.hdf5\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2000/2000 [==============================] - 1287s 644ms/step - loss: 0.2486 - acc: 0.8913\n",
            "Epoch 2/5\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9420\n",
            "Epoch 00002: loss improved from 0.24859 to 0.13998, saving model to unet_membrane.hdf5\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2000/2000 [==============================] - 1222s 611ms/step - loss: 0.1400 - acc: 0.9420\n",
            "Epoch 3/5\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9537\n",
            "Epoch 00003: loss improved from 0.13998 to 0.10964, saving model to unet_membrane.hdf5\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2000/2000 [==============================] - 1223s 612ms/step - loss: 0.1096 - acc: 0.9537\n",
            "Epoch 4/5\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9608\n",
            "Epoch 00004: loss improved from 0.10964 to 0.09164, saving model to unet_membrane.hdf5\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2000/2000 [==============================] - 1226s 613ms/step - loss: 0.0916 - acc: 0.9608\n",
            "Epoch 5/5\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9651\n",
            "Epoch 00005: loss improved from 0.09164 to 0.08091, saving model to unet_membrane.hdf5\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2000/2000 [==============================] - 1226s 613ms/step - loss: 0.0809 - acc: 0.9651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4568c673c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZEN-B6PXNy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    for i in range(num_image):\n",
        "        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        yield img\n",
        "        \n",
        "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZExx6j-PUttL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8cdbd03-f1b0-49f6-c1b0-203dbadc8871"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "testGene = testGenerator(\"data/membrane/test\")\n",
        "model = unet()\n",
        "model.load_weights(\"unet_membrane.hdf5\")\n",
        "results = model.predict_generator(testGene,30,verbose=1)\n",
        "saveResult(\"data/membrane/test\",results)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 128, 128, 1)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_23 (OctaveConv2D) [(None, 256, 256, 56 1152        input_2[0][0]                    \n",
            "                                                                 average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_23[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 256, 256, 56) 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 128, 128, 8)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_24 (OctaveConv2D) [(None, 256, 256, 56 36864       activation_45[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_24[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 256, 256, 56) 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 128, 128, 8)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 128, 128, 56) 0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 8)    0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_25 (OctaveConv2D) [(None, 128, 128, 11 73728       max_pooling2d_8[0][0]            \n",
            "                                                                 max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 128, 128, 112 448         octave_conv2d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_25[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 128, 128, 112 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 64, 64, 16)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_26 (OctaveConv2D) [(None, 128, 128, 11 147456      activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 128, 128, 112 448         octave_conv2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_26[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 128, 128, 112 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 64, 64, 16)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 64, 64, 112)  0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 16)   0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_27 (OctaveConv2D) [(None, 64, 64, 224) 294912      max_pooling2d_10[0][0]           \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_27[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_27[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 64, 64, 224)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 32)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_28 (OctaveConv2D) [(None, 64, 64, 224) 589824      activation_53[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_28[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_28[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 64, 64, 224)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 32)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 224)  0           activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 32)   0           activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_29 (OctaveConv2D) [(None, 32, 32, 448) 1179648     max_pooling2d_12[0][0]           \n",
            "                                                                 max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_29[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 448)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_30 (OctaveConv2D) [(None, 32, 32, 448) 2359296     activation_57[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_30[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 32, 32, 448)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 16, 16, 448)  0           activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 64)     0           activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_31 (OctaveConv2D) [(None, 16, 16, 896) 4718592     max_pooling2d_14[0][0]           \n",
            "                                                                 max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 896)  3584        octave_conv2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 8, 8, 128)    512         octave_conv2d_31[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 896)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 128)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 896)  0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 8, 8, 128)    0           activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_32 (OctaveConv2D) [(None, 16, 16, 896) 9437184     dropout_4[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 896)  3584        octave_conv2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 8, 8, 128)    512         octave_conv2d_32[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 896)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 128)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 896)  0           activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 8, 8, 128)    0           activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_33 (OctaveConv2D) [(None, 32, 32, 448) 4718592     dropout_6[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_33[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 32, 32, 448)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 896)  0           activation_59[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 128)  0           activation_60[0][0]              \n",
            "                                                                 activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_34 (OctaveConv2D) [(None, 32, 32, 448) 4718592     concatenate_8[0][0]              \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_34[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_34[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 32, 32, 448)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 64)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_35 (OctaveConv2D) [(None, 32, 32, 448) 2359296     activation_67[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 32, 32, 448)  1792        octave_conv2d_35[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 16, 16, 64)   256         octave_conv2d_35[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 32, 32, 448)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 64)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_36 (OctaveConv2D) [(None, 64, 64, 224) 1179648     activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_36[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_36[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 64, 64, 224)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 32, 32, 32)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 64, 64, 448)  0           activation_55[0][0]              \n",
            "                                                                 activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 64)   0           activation_56[0][0]              \n",
            "                                                                 activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_37 (OctaveConv2D) [(None, 64, 64, 224) 1179648     concatenate_10[0][0]             \n",
            "                                                                 concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_37[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 64, 64, 224)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 32, 32, 32)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_38 (OctaveConv2D) [(None, 64, 64, 224) 589824      activation_73[0][0]              \n",
            "                                                                 activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 64, 64, 224)  896         octave_conv2d_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 32, 32, 32)   128         octave_conv2d_38[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 64, 64, 224)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 32, 32, 32)   0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_39 (OctaveConv2D) [(None, 128, 128, 11 294912      activation_75[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 128, 128, 112 448         octave_conv2d_39[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_39[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 128, 128, 112 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 64, 64, 16)   0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 128, 128, 224 0           activation_51[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 64, 64, 32)   0           activation_52[0][0]              \n",
            "                                                                 activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_40 (OctaveConv2D) [(None, 128, 128, 11 294912      concatenate_12[0][0]             \n",
            "                                                                 concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 128, 128, 112 448         octave_conv2d_40[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_40[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 128, 128, 112 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 64, 64, 16)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_41 (OctaveConv2D) [(None, 128, 128, 11 147456      activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 128, 128, 112 448         octave_conv2d_41[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 64, 64, 16)   64          octave_conv2d_41[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 128, 128, 112 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 64, 64, 16)   0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_42 (OctaveConv2D) [(None, 256, 256, 56 73728       activation_81[0][0]              \n",
            "                                                                 activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_42[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_42[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 256, 256, 56) 0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 128, 128, 8)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 256, 256, 112 0           activation_47[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 128, 128, 16) 0           activation_48[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_43 (OctaveConv2D) [(None, 256, 256, 56 73728       concatenate_14[0][0]             \n",
            "                                                                 concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_43[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 256, 256, 56) 0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 128, 128, 8)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_44 (OctaveConv2D) [(None, 256, 256, 56 36864       activation_85[0][0]              \n",
            "                                                                 activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 256, 256, 56) 224         octave_conv2d_44[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 128, 128, 8)  32          octave_conv2d_44[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 256, 256, 56) 0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 128, 128, 8)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "octave_conv2d_45 (OctaveConv2D) (None, 256, 256, 32) 18432       activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 256, 256, 32) 0           octave_conv2d_45[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 1)  33          activation_89[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 34,551,713\n",
            "Trainable params: 34,538,017\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "30/30 [==============================] - 9s 293ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}